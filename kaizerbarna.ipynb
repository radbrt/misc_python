{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barna = codecs.open('/home/jovyan/Data/allebarna.txt', encoding='utf8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaizer = codecs.open('/home/jovyan/Data/kaizers.txt', encoding='utf8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "barna = [vits for vits in barna if vits[0:4]=='Alle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(barna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Den skal vær mann som kan gå med min hatt\\n',\n",
       " 'Den skal vær kald som tar øve mi makt\\n',\n",
       " 'Den skal ha nr 42 for å gå med mine sko\\n',\n",
       " 'Men han må ha sin egen pistol\\n',\n",
       " 'for du vett kva som står i testamentet\\n',\n",
       " 'Du vett kva som står i testamentet\\n',\n",
       " 'At den som tar hånd om min Constanze\\n',\n",
       " 'får min hatt, får mine sko, får mitt extravanganza\\n',\n",
       " 'Ta kontroll på kontinentet\\n',\n",
       " 'Og eg ber om å bli godt parfymert\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaizer[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alle barna ble etterforsker, unntatt Abel, han ble konstabel.\\n',\n",
       " 'Alle barna hadde liten nese, unntatt Abel, han hadde snabel.\\n',\n",
       " 'Alle barna hadde liten tiss, unntatt Abel, han hadde en kjempe snabel.\\n',\n",
       " 'Alle barna var greie, unntatt Abel, han var irritabel.\\n',\n",
       " 'Alle barna hadde problemer med å gå på do unntatt Abel, han la en kabel.\\n',\n",
       " 'Alle barne så på det skitne vannet, unntatt Ada, hun bada.\\n',\n",
       " 'Alle barna ble tatt til fange, unntatt Ada, hun kjørte vekk med sin lada.\\n',\n",
       " 'Alle barna vraket Ferrariene sine unntatt Ada, hun kjørte rundt i en strøken Lada.\\n',\n",
       " 'Alle barna kjørte Volvo unntatt Ada, hun kjørte Lada.\\n',\n",
       " 'Alle barna kjørte elbil, unntatt Adrian, han måtte lad’an.\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barna[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abC\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alle = kaizer + barna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaizerbarna = [sent.replace(\"\\n\", \"\").lower() for sent in alle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den skal vær mann som kan gå med min hatt',\n",
       " 'den skal vær kald som tar øve mi makt',\n",
       " 'den skal ha nr 42 for å gå med mine sko',\n",
       " 'men han må ha sin egen pistol',\n",
       " 'for du vett kva som står i testamentet',\n",
       " 'du vett kva som står i testamentet',\n",
       " 'at den som tar hånd om min constanze',\n",
       " 'får min hatt, får mine sko, får mitt extravanganza',\n",
       " 'ta kontroll på kontinentet',\n",
       " 'og eg ber om å bli godt parfymert']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaizerbarna[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "seq_length = 10\n",
    "\n",
    "for line in kaizerbarna:\n",
    "    if len(line)<=10:\n",
    "        seqs.append(line)\n",
    "    else:\n",
    "        for i in range(seq_length, len(line)):\n",
    "            seqs.append(line[i-seq_length:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den skal væ',\n",
       " 'en skal vær',\n",
       " 'n skal vær ',\n",
       " ' skal vær m',\n",
       " 'skal vær ma',\n",
       " 'kal vær man',\n",
       " 'al vær mann',\n",
       " 'l vær mann ',\n",
       " ' vær mann s',\n",
       " 'vær mann so']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98307"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(''.join(seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "realseqs = [seq for seq in seqs if len(seq)==11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98286"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(realseqs))))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '%': 2,\n",
       " '&': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '/': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '4': 14,\n",
       " '5': 15,\n",
       " '6': 16,\n",
       " '7': 17,\n",
       " '8': 18,\n",
       " '9': 19,\n",
       " ':': 20,\n",
       " ';': 21,\n",
       " '?': 22,\n",
       " '`': 23,\n",
       " 'a': 24,\n",
       " 'b': 25,\n",
       " 'c': 26,\n",
       " 'd': 27,\n",
       " 'e': 28,\n",
       " 'f': 29,\n",
       " 'g': 30,\n",
       " 'h': 31,\n",
       " 'i': 32,\n",
       " 'j': 33,\n",
       " 'k': 34,\n",
       " 'l': 35,\n",
       " 'm': 36,\n",
       " 'n': 37,\n",
       " 'o': 38,\n",
       " 'p': 39,\n",
       " 'q': 40,\n",
       " 'r': 41,\n",
       " 's': 42,\n",
       " 't': 43,\n",
       " 'u': 44,\n",
       " 'v': 45,\n",
       " 'w': 46,\n",
       " 'x': 47,\n",
       " 'y': 48,\n",
       " 'z': 49,\n",
       " '\\xa0': 50,\n",
       " '«': 51,\n",
       " '»': 52,\n",
       " 'å': 53,\n",
       " 'æ': 54,\n",
       " 'è': 55,\n",
       " 'é': 56,\n",
       " 'ñ': 57,\n",
       " 'ô': 58,\n",
       " 'ø': 59,\n",
       " '’': 60,\n",
       " '…': 61}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LabelEncoder().fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in realseqs:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    # store\n",
    "    sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 28, 37, ...,  0, 45, 54],\n",
       "       [28, 37,  0, ..., 45, 54, 41],\n",
       "       [37,  0, 42, ..., 54, 41,  0],\n",
       "       ...,\n",
       "       [32, 34, 34, ..., 35, 53, 42],\n",
       "       [34, 34, 28, ..., 53, 42, 28],\n",
       "       [34, 28,  0, ..., 42, 28,  8]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np_sequences[:,:-1], np_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 28, 37, 0, 42, 34, 24, 35, 0, 45, 54]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "vocab_size = len(set(''.join(seqs)))\n",
    "\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 75)                41400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 62)                4712      \n",
      "=================================================================\n",
      "Total params: 46,112\n",
      "Trainable params: 46,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98286 samples\n",
      "Epoch 1/100\n",
      "98286/98286 - 25s - loss: 2.1862 - accuracy: 0.3716\n",
      "Epoch 2/100\n",
      "98286/98286 - 24s - loss: 1.7719 - accuracy: 0.4658\n",
      "Epoch 3/100\n",
      "98286/98286 - 24s - loss: 1.6691 - accuracy: 0.4969\n",
      "Epoch 4/100\n",
      "98286/98286 - 24s - loss: 1.6075 - accuracy: 0.5131\n",
      "Epoch 5/100\n",
      "98286/98286 - 24s - loss: 1.5617 - accuracy: 0.5268\n",
      "Epoch 6/100\n",
      "98286/98286 - 24s - loss: 1.5237 - accuracy: 0.5381\n",
      "Epoch 7/100\n",
      "98286/98286 - 24s - loss: 1.4910 - accuracy: 0.5476\n",
      "Epoch 8/100\n",
      "98286/98286 - 24s - loss: 1.4619 - accuracy: 0.5567\n",
      "Epoch 9/100\n",
      "98286/98286 - 23s - loss: 1.4359 - accuracy: 0.5650\n",
      "Epoch 10/100\n",
      "98286/98286 - 24s - loss: 1.4126 - accuracy: 0.5725\n",
      "Epoch 11/100\n",
      "98286/98286 - 24s - loss: 1.3904 - accuracy: 0.5787\n",
      "Epoch 12/100\n",
      "98286/98286 - 24s - loss: 1.3700 - accuracy: 0.5837\n",
      "Epoch 13/100\n",
      "98286/98286 - 24s - loss: 1.3521 - accuracy: 0.5888\n",
      "Epoch 14/100\n",
      "98286/98286 - 24s - loss: 1.3341 - accuracy: 0.5946\n",
      "Epoch 15/100\n",
      "98286/98286 - 24s - loss: 1.3177 - accuracy: 0.5993\n",
      "Epoch 16/100\n",
      "98286/98286 - 25s - loss: 1.3015 - accuracy: 0.6042\n",
      "Epoch 17/100\n",
      "98286/98286 - 25s - loss: 1.2874 - accuracy: 0.6072\n",
      "Epoch 18/100\n",
      "98286/98286 - 25s - loss: 1.2729 - accuracy: 0.6135\n",
      "Epoch 19/100\n",
      "98286/98286 - 24s - loss: 1.2600 - accuracy: 0.6176\n",
      "Epoch 20/100\n",
      "98286/98286 - 25s - loss: 1.2455 - accuracy: 0.6205\n",
      "Epoch 21/100\n",
      "98286/98286 - 25s - loss: 1.2341 - accuracy: 0.6261\n",
      "Epoch 22/100\n",
      "98286/98286 - 24s - loss: 1.2219 - accuracy: 0.6285\n",
      "Epoch 23/100\n",
      "98286/98286 - 24s - loss: 1.2096 - accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "98286/98286 - 24s - loss: 1.1985 - accuracy: 0.6333\n",
      "Epoch 25/100\n",
      "98286/98286 - 23s - loss: 1.1880 - accuracy: 0.6382\n",
      "Epoch 26/100\n",
      "98286/98286 - 24s - loss: 1.1776 - accuracy: 0.6410\n",
      "Epoch 27/100\n",
      "98286/98286 - 24s - loss: 1.1678 - accuracy: 0.6445\n",
      "Epoch 28/100\n",
      "98286/98286 - 24s - loss: 1.1576 - accuracy: 0.6477\n",
      "Epoch 29/100\n",
      "98286/98286 - 24s - loss: 1.1486 - accuracy: 0.6489\n",
      "Epoch 30/100\n",
      "98286/98286 - 24s - loss: 1.1398 - accuracy: 0.6516\n",
      "Epoch 31/100\n",
      "98286/98286 - 24s - loss: 1.1308 - accuracy: 0.6534\n",
      "Epoch 32/100\n",
      "98286/98286 - 25s - loss: 1.1218 - accuracy: 0.6571\n",
      "Epoch 33/100\n",
      "98286/98286 - 25s - loss: 1.1141 - accuracy: 0.6607\n",
      "Epoch 34/100\n",
      "98286/98286 - 25s - loss: 1.1063 - accuracy: 0.6622\n",
      "Epoch 35/100\n",
      "98286/98286 - 24s - loss: 1.0998 - accuracy: 0.6636\n",
      "Epoch 36/100\n",
      "98286/98286 - 23s - loss: 1.0921 - accuracy: 0.6671\n",
      "Epoch 37/100\n",
      "98286/98286 - 24s - loss: 1.0850 - accuracy: 0.6682\n",
      "Epoch 38/100\n",
      "98286/98286 - 24s - loss: 1.0781 - accuracy: 0.6706\n",
      "Epoch 39/100\n",
      "98286/98286 - 23s - loss: 1.0714 - accuracy: 0.6723\n",
      "Epoch 40/100\n",
      "98286/98286 - 24s - loss: 1.0659 - accuracy: 0.6740\n",
      "Epoch 41/100\n",
      "98286/98286 - 24s - loss: 1.0589 - accuracy: 0.6761\n",
      "Epoch 42/100\n",
      "98286/98286 - 24s - loss: 1.0531 - accuracy: 0.6789\n",
      "Epoch 43/100\n",
      "98286/98286 - 24s - loss: 1.0484 - accuracy: 0.6792\n",
      "Epoch 44/100\n",
      "98286/98286 - 24s - loss: 1.0433 - accuracy: 0.6816\n",
      "Epoch 45/100\n",
      "98286/98286 - 24s - loss: 1.0378 - accuracy: 0.6828\n",
      "Epoch 46/100\n",
      "98286/98286 - 24s - loss: 1.0327 - accuracy: 0.6839\n",
      "Epoch 47/100\n",
      "98286/98286 - 24s - loss: 1.0264 - accuracy: 0.6870\n",
      "Epoch 48/100\n",
      "98286/98286 - 24s - loss: 1.0225 - accuracy: 0.6879\n",
      "Epoch 49/100\n",
      "98286/98286 - 23s - loss: 1.0180 - accuracy: 0.6888\n",
      "Epoch 50/100\n",
      "98286/98286 - 23s - loss: 1.0127 - accuracy: 0.6906\n",
      "Epoch 51/100\n",
      "98286/98286 - 23s - loss: 1.0101 - accuracy: 0.6907\n",
      "Epoch 52/100\n",
      "98286/98286 - 23s - loss: 1.0052 - accuracy: 0.6927\n",
      "Epoch 53/100\n",
      "98286/98286 - 23s - loss: 1.0009 - accuracy: 0.6933\n",
      "Epoch 54/100\n",
      "98286/98286 - 23s - loss: 0.9978 - accuracy: 0.6945\n",
      "Epoch 55/100\n",
      "98286/98286 - 24s - loss: 0.9926 - accuracy: 0.6968\n",
      "Epoch 56/100\n",
      "98286/98286 - 23s - loss: 0.9897 - accuracy: 0.6965\n",
      "Epoch 57/100\n",
      "98286/98286 - 23s - loss: 0.9868 - accuracy: 0.6972\n",
      "Epoch 58/100\n",
      "98286/98286 - 23s - loss: 0.9823 - accuracy: 0.6986\n",
      "Epoch 59/100\n",
      "98286/98286 - 23s - loss: 0.9791 - accuracy: 0.6997\n",
      "Epoch 60/100\n",
      "98286/98286 - 23s - loss: 0.9763 - accuracy: 0.7010\n",
      "Epoch 61/100\n",
      "98286/98286 - 23s - loss: 0.9720 - accuracy: 0.7017\n",
      "Epoch 62/100\n",
      "98286/98286 - 23s - loss: 0.9691 - accuracy: 0.7018\n",
      "Epoch 63/100\n",
      "98286/98286 - 23s - loss: 0.9665 - accuracy: 0.7035\n",
      "Epoch 64/100\n",
      "98286/98286 - 23s - loss: 0.9633 - accuracy: 0.7048\n",
      "Epoch 65/100\n",
      "98286/98286 - 23s - loss: 0.9603 - accuracy: 0.7057\n",
      "Epoch 66/100\n",
      "98286/98286 - 23s - loss: 0.9585 - accuracy: 0.7049\n",
      "Epoch 67/100\n",
      "98286/98286 - 23s - loss: 0.9550 - accuracy: 0.7069\n",
      "Epoch 68/100\n",
      "98286/98286 - 23s - loss: 0.9516 - accuracy: 0.7072\n",
      "Epoch 69/100\n",
      "98286/98286 - 23s - loss: 0.9499 - accuracy: 0.7071\n",
      "Epoch 70/100\n",
      "98286/98286 - 23s - loss: 0.9460 - accuracy: 0.7090\n",
      "Epoch 71/100\n",
      "98286/98286 - 23s - loss: 0.9447 - accuracy: 0.7097\n",
      "Epoch 72/100\n",
      "98286/98286 - 23s - loss: 0.9406 - accuracy: 0.7105\n",
      "Epoch 73/100\n",
      "98286/98286 - 23s - loss: 0.9403 - accuracy: 0.7103\n",
      "Epoch 74/100\n",
      "98286/98286 - 23s - loss: 0.9384 - accuracy: 0.7116\n",
      "Epoch 75/100\n",
      "98286/98286 - 23s - loss: 0.9359 - accuracy: 0.7121\n",
      "Epoch 76/100\n",
      "98286/98286 - 23s - loss: 0.9335 - accuracy: 0.7120\n",
      "Epoch 77/100\n",
      "98286/98286 - 23s - loss: 0.9323 - accuracy: 0.7121\n",
      "Epoch 78/100\n",
      "98286/98286 - 23s - loss: 0.9282 - accuracy: 0.7147\n",
      "Epoch 79/100\n",
      "98286/98286 - 23s - loss: 0.9277 - accuracy: 0.7151\n",
      "Epoch 80/100\n",
      "98286/98286 - 23s - loss: 0.9240 - accuracy: 0.7152\n",
      "Epoch 81/100\n",
      "98286/98286 - 23s - loss: 0.9240 - accuracy: 0.7147\n",
      "Epoch 82/100\n",
      "98286/98286 - 23s - loss: 0.9223 - accuracy: 0.7160\n",
      "Epoch 83/100\n",
      "98286/98286 - 23s - loss: 0.9208 - accuracy: 0.7162\n",
      "Epoch 84/100\n",
      "98286/98286 - 24s - loss: 0.9170 - accuracy: 0.7167\n",
      "Epoch 85/100\n",
      "98286/98286 - 23s - loss: 0.9155 - accuracy: 0.7176\n",
      "Epoch 86/100\n",
      "98286/98286 - 23s - loss: 0.9148 - accuracy: 0.7171\n",
      "Epoch 87/100\n",
      "98286/98286 - 23s - loss: 0.9130 - accuracy: 0.7185\n",
      "Epoch 88/100\n",
      "98286/98286 - 23s - loss: 0.9120 - accuracy: 0.7187\n",
      "Epoch 89/100\n",
      "98286/98286 - 23s - loss: 0.9090 - accuracy: 0.7203\n",
      "Epoch 90/100\n",
      "98286/98286 - 23s - loss: 0.9081 - accuracy: 0.7195\n",
      "Epoch 91/100\n",
      "98286/98286 - 23s - loss: 0.9078 - accuracy: 0.7202\n",
      "Epoch 92/100\n",
      "98286/98286 - 23s - loss: 0.9052 - accuracy: 0.7207\n",
      "Epoch 93/100\n",
      "98286/98286 - 23s - loss: 0.9042 - accuracy: 0.7223\n",
      "Epoch 94/100\n",
      "98286/98286 - 23s - loss: 0.9024 - accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "98286/98286 - 23s - loss: 0.9000 - accuracy: 0.7217\n",
      "Epoch 96/100\n",
      "98286/98286 - 23s - loss: 0.8990 - accuracy: 0.7216\n",
      "Epoch 97/100\n",
      "98286/98286 - 23s - loss: 0.8988 - accuracy: 0.7219\n",
      "Epoch 98/100\n",
      "98286/98286 - 23s - loss: 0.8960 - accuracy: 0.7231\n",
      "Epoch 99/100\n",
      "98286/98286 - 23s - loss: 0.8953 - accuracy: 0.7229\n",
      "Epoch 100/100\n",
      "98286/98286 - 23s - loss: 0.8941 - accuracy: 0.7242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9bed2ee7d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "håndtverkelen. ute pil sofsttekrerse unntatt marte, hun hadde den på det vanne ikken unntatt tord, han var stein. leve en mieter. legg. det det samt på skolen \n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 10, 'håndtverk', 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tords = [line for line in kaizerbarna if \"stein\" in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['men tiå har vært snill mot mitt håndtverk. eg la ner stein for stein. ',\n",
       " 'og ro i land, for denne steinen bærer ditt navn.',\n",
       " 'for ting har gått over stokk og stein her ',\n",
       " 'alle barna likte jenter unntatt einar(tim), han likte steinar(kim).',\n",
       " 'alle barna var fattige unntatt eirik, han var steinrik.',\n",
       " 'alle barna var snille unntatt gunn, hun kastet en stein på en hund.',\n",
       " 'alle barna fikk egg, unntatt karen, hun lekte stein saks papir med påskeharen.',\n",
       " 'alle barna fikk egg, unntatt karen, hun lekte stein saks papir med påskeharen.',\n",
       " 'alle hannover-spillerne kunne spille fotball, unntatt moa, han hadde stein i skoa.',\n",
       " 'alle barna gikk på ski unntatt stein, han manglet bein.',\n",
       " 'alle barna spiste suppe, unntatt svein, han spiste småstein.',\n",
       " 'alle barna gnager på et bein, unntatt svein, han gnager på en liten stein.',\n",
       " 'alle barna kastet snøball på læreren unntatt svein, han kastet stein.',\n",
       " 'alle barna hoppet paradis unntatt svein, han var stein.',\n",
       " 'alle barna landet trygt etter fallskjermhoppet, unntatt torstein han landet i en skorstein.',\n",
       " 'alle barna så inn i peisen unntatt torstein, han var skorstein.',\n",
       " 'alle barna fikk bo i lavvo, unntatt øystein, han var en villrein.']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
