{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barna = codecs.open('/home/jovyan/Data/allebarna.txt', encoding='utf8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaizer = codecs.open('/home/jovyan/Data/kaizers.txt', encoding='utf8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "barna = [vits for vits in barna if vits[0:4]=='Alle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(barna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Den skal vær mann som kan gå med min hatt\\n',\n",
       " 'Den skal vær kald som tar øve mi makt\\n',\n",
       " 'Den skal ha nr 42 for å gå med mine sko\\n',\n",
       " 'Men han må ha sin egen pistol\\n',\n",
       " 'for du vett kva som står i testamentet\\n',\n",
       " 'Du vett kva som står i testamentet\\n',\n",
       " 'At den som tar hånd om min Constanze\\n',\n",
       " 'får min hatt, får mine sko, får mitt extravanganza\\n',\n",
       " 'Ta kontroll på kontinentet\\n',\n",
       " 'Og eg ber om å bli godt parfymert\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaizer[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alle barna ble etterforsker, unntatt Abel, han ble konstabel.\\n',\n",
       " 'Alle barna hadde liten nese, unntatt Abel, han hadde snabel.\\n',\n",
       " 'Alle barna hadde liten tiss, unntatt Abel, han hadde en kjempe snabel.\\n',\n",
       " 'Alle barna var greie, unntatt Abel, han var irritabel.\\n',\n",
       " 'Alle barna hadde problemer med å gå på do unntatt Abel, han la en kabel.\\n',\n",
       " 'Alle barne så på det skitne vannet, unntatt Ada, hun bada.\\n',\n",
       " 'Alle barna ble tatt til fange, unntatt Ada, hun kjørte vekk med sin lada.\\n',\n",
       " 'Alle barna vraket Ferrariene sine unntatt Ada, hun kjørte rundt i en strøken Lada.\\n',\n",
       " 'Alle barna kjørte Volvo unntatt Ada, hun kjørte Lada.\\n',\n",
       " 'Alle barna kjørte elbil, unntatt Adrian, han måtte lad’an.\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barna[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abC\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alle = kaizer + barna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2336"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaizerbarna = [sent.replace(\"\\n\", \"\").lower() for sent in alle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den skal vær mann som kan gå med min hatt',\n",
       " 'den skal vær kald som tar øve mi makt',\n",
       " 'den skal ha nr 42 for å gå med mine sko',\n",
       " 'men han må ha sin egen pistol',\n",
       " 'for du vett kva som står i testamentet',\n",
       " 'du vett kva som står i testamentet',\n",
       " 'at den som tar hånd om min constanze',\n",
       " 'får min hatt, får mine sko, får mitt extravanganza',\n",
       " 'ta kontroll på kontinentet',\n",
       " 'og eg ber om å bli godt parfymert']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaizerbarna[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "seq_length = 10\n",
    "\n",
    "for line in kaizerbarna:\n",
    "    if len(line)<=10:\n",
    "        seqs.append(line)\n",
    "    else:\n",
    "        for i in range(seq_length, len(line)):\n",
    "            seqs.append(line[i-seq_length:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den skal væ',\n",
       " 'en skal vær',\n",
       " 'n skal vær ',\n",
       " ' skal vær m',\n",
       " 'skal vær ma',\n",
       " 'kal vær man',\n",
       " 'al vær mann',\n",
       " 'l vær mann ',\n",
       " ' vær mann s',\n",
       " 'vær mann so']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98307"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(''.join(seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "realseqs = [seq for seq in seqs if len(seq)==11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98286"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(realseqs))))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '%': 2,\n",
       " '&': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '/': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '4': 14,\n",
       " '5': 15,\n",
       " '6': 16,\n",
       " '7': 17,\n",
       " '8': 18,\n",
       " '9': 19,\n",
       " ':': 20,\n",
       " ';': 21,\n",
       " '?': 22,\n",
       " '`': 23,\n",
       " 'a': 24,\n",
       " 'b': 25,\n",
       " 'c': 26,\n",
       " 'd': 27,\n",
       " 'e': 28,\n",
       " 'f': 29,\n",
       " 'g': 30,\n",
       " 'h': 31,\n",
       " 'i': 32,\n",
       " 'j': 33,\n",
       " 'k': 34,\n",
       " 'l': 35,\n",
       " 'm': 36,\n",
       " 'n': 37,\n",
       " 'o': 38,\n",
       " 'p': 39,\n",
       " 'q': 40,\n",
       " 'r': 41,\n",
       " 's': 42,\n",
       " 't': 43,\n",
       " 'u': 44,\n",
       " 'v': 45,\n",
       " 'w': 46,\n",
       " 'x': 47,\n",
       " 'y': 48,\n",
       " 'z': 49,\n",
       " '\\xa0': 50,\n",
       " '«': 51,\n",
       " '»': 52,\n",
       " 'å': 53,\n",
       " 'æ': 54,\n",
       " 'è': 55,\n",
       " 'é': 56,\n",
       " 'ñ': 57,\n",
       " 'ô': 58,\n",
       " 'ø': 59,\n",
       " '’': 60,\n",
       " '…': 61}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LabelEncoder().fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in realseqs:\n",
    "    # integer encode line\n",
    "    encoded_seq = [mapping[char] for char in line]\n",
    "    # store\n",
    "    sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 28, 37, ...,  0, 45, 54],\n",
       "       [28, 37,  0, ..., 45, 54, 41],\n",
       "       [37,  0, 42, ..., 54, 41,  0],\n",
       "       ...,\n",
       "       [32, 34, 34, ..., 35, 53, 42],\n",
       "       [34, 34, 28, ..., 53, 42, 28],\n",
       "       [34, 28,  0, ..., 42, 28,  8]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np_sequences[:,:-1], np_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 28, 37, 0, 42, 34, 24, 35, 0, 45, 54]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "vocab_size = len(set(''.join(seqs)))\n",
    "\n",
    "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = array(sequences)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(GRU(512, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(512, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributedDense(1))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_20 (GRU)                 (None, 72)                29376     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               37376     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 62)                31806     \n",
      "=================================================================\n",
      "Total params: 98,558\n",
      "Trainable params: 98,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(GRU(72, recurrent_activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98286 samples\n",
      "Epoch 1/100\n",
      "98286/98286 [==============================] - 12s 119us/sample - loss: 1.9306 - accuracy: 0.4296\n",
      "Epoch 2/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.6115 - accuracy: 0.5033\n",
      "Epoch 3/100\n",
      "98286/98286 [==============================] - 11s 108us/sample - loss: 1.5209 - accuracy: 0.5324\n",
      "Epoch 4/100\n",
      "98286/98286 [==============================] - 12s 120us/sample - loss: 1.4548 - accuracy: 0.5525\n",
      "Epoch 5/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.3999 - accuracy: 0.5705\n",
      "Epoch 6/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.3535 - accuracy: 0.5853\n",
      "Epoch 7/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.3137 - accuracy: 0.5965\n",
      "Epoch 8/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.2772 - accuracy: 0.6072\n",
      "Epoch 9/100\n",
      "98286/98286 [==============================] - 11s 107us/sample - loss: 1.2463 - accuracy: 0.6159\n",
      "Epoch 10/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.2192 - accuracy: 0.6231\n",
      "Epoch 11/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.1930 - accuracy: 0.6297\n",
      "Epoch 12/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.1681 - accuracy: 0.6362\n",
      "Epoch 13/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.1473 - accuracy: 0.6428\n",
      "Epoch 14/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.1280 - accuracy: 0.6499\n",
      "Epoch 15/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.1070 - accuracy: 0.6541\n",
      "Epoch 16/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.0897 - accuracy: 0.6594\n",
      "Epoch 17/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.0727 - accuracy: 0.6628\n",
      "Epoch 18/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.0569 - accuracy: 0.6690\n",
      "Epoch 19/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 1.0402 - accuracy: 0.6714\n",
      "Epoch 20/100\n",
      "98286/98286 [==============================] - 10s 107us/sample - loss: 1.0274 - accuracy: 0.6755\n",
      "Epoch 21/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.0130 - accuracy: 0.6808\n",
      "Epoch 22/100\n",
      "98286/98286 [==============================] - 11s 115us/sample - loss: 1.0056 - accuracy: 0.6831\n",
      "Epoch 23/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 1.0411 - accuracy: 0.6697\n",
      "Epoch 24/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.9841 - accuracy: 0.6889\n",
      "Epoch 25/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.9642 - accuracy: 0.6935\n",
      "Epoch 26/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.9491 - accuracy: 0.6975\n",
      "Epoch 27/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.9381 - accuracy: 0.7024\n",
      "Epoch 28/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.9306 - accuracy: 0.7024\n",
      "Epoch 29/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.9223 - accuracy: 0.7054\n",
      "Epoch 30/100\n",
      "98286/98286 [==============================] - ETA: 0s - loss: 0.9159 - accuracy: 0.70 - 10s 106us/sample - loss: 0.9157 - accuracy: 0.7072\n",
      "Epoch 31/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.9090 - accuracy: 0.7095\n",
      "Epoch 32/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.9027 - accuracy: 0.7107\n",
      "Epoch 33/100\n",
      "98286/98286 [==============================] - 11s 108us/sample - loss: 0.8956 - accuracy: 0.7134\n",
      "Epoch 34/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8873 - accuracy: 0.7154\n",
      "Epoch 35/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8810 - accuracy: 0.7171\n",
      "Epoch 36/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8758 - accuracy: 0.7177\n",
      "Epoch 37/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8657 - accuracy: 0.7202\n",
      "Epoch 38/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.8578 - accuracy: 0.7237\n",
      "Epoch 39/100\n",
      "98286/98286 [==============================] - 11s 108us/sample - loss: 0.8900 - accuracy: 0.7126\n",
      "Epoch 40/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8550 - accuracy: 0.7237\n",
      "Epoch 41/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.8358 - accuracy: 0.7301\n",
      "Epoch 42/100\n",
      "98286/98286 [==============================] - 11s 107us/sample - loss: 0.8307 - accuracy: 0.7310\n",
      "Epoch 43/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8242 - accuracy: 0.7339\n",
      "Epoch 44/100\n",
      "98286/98286 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.73 - 10s 105us/sample - loss: 0.8229 - accuracy: 0.7333\n",
      "Epoch 45/100\n",
      "98286/98286 [==============================] - 10s 107us/sample - loss: 0.8153 - accuracy: 0.7362\n",
      "Epoch 46/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.8106 - accuracy: 0.7372\n",
      "Epoch 47/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.8059 - accuracy: 0.7379\n",
      "Epoch 48/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.8006 - accuracy: 0.7396\n",
      "Epoch 49/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7976 - accuracy: 0.7413\n",
      "Epoch 50/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7910 - accuracy: 0.7436\n",
      "Epoch 51/100\n",
      "98286/98286 [==============================] - 11s 107us/sample - loss: 0.7891 - accuracy: 0.7438\n",
      "Epoch 52/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7801 - accuracy: 0.7457\n",
      "Epoch 53/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7756 - accuracy: 0.7477\n",
      "Epoch 54/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7717 - accuracy: 0.7490\n",
      "Epoch 55/100\n",
      "98286/98286 [==============================] - 11s 107us/sample - loss: 0.7690 - accuracy: 0.7491\n",
      "Epoch 56/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7640 - accuracy: 0.7511\n",
      "Epoch 57/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7610 - accuracy: 0.7514\n",
      "Epoch 58/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7531 - accuracy: 0.7543\n",
      "Epoch 59/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7512 - accuracy: 0.7540\n",
      "Epoch 60/100\n",
      "98286/98286 [==============================] - 11s 109us/sample - loss: 0.7492 - accuracy: 0.7557\n",
      "Epoch 61/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7449 - accuracy: 0.7564\n",
      "Epoch 62/100\n",
      "98286/98286 [==============================] - 10s 106us/sample - loss: 0.7425 - accuracy: 0.7574\n",
      "Epoch 63/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7363 - accuracy: 0.7593\n",
      "Epoch 64/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7377 - accuracy: 0.7584\n",
      "Epoch 65/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7321 - accuracy: 0.7611\n",
      "Epoch 66/100\n",
      "98286/98286 [==============================] - 10s 104us/sample - loss: 0.7275 - accuracy: 0.7619\n",
      "Epoch 67/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7225 - accuracy: 0.7626\n",
      "Epoch 68/100\n",
      "98286/98286 [==============================] - 10s 105us/sample - loss: 0.7194 - accuracy: 0.7638\n",
      "Epoch 69/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.7192 - accuracy: 0.7639\n",
      "Epoch 70/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.7176 - accuracy: 0.7650\n",
      "Epoch 71/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.7161 - accuracy: 0.7646\n",
      "Epoch 72/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.7088 - accuracy: 0.7680\n",
      "Epoch 73/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.7064 - accuracy: 0.7688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.7081 - accuracy: 0.7676\n",
      "Epoch 75/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.7010 - accuracy: 0.7694\n",
      "Epoch 76/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6978 - accuracy: 0.7709\n",
      "Epoch 77/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.6968 - accuracy: 0.7708\n",
      "Epoch 78/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6983 - accuracy: 0.7709\n",
      "Epoch 79/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6962 - accuracy: 0.7710\n",
      "Epoch 80/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6899 - accuracy: 0.7724\n",
      "Epoch 81/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6905 - accuracy: 0.7718\n",
      "Epoch 82/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6860 - accuracy: 0.7736\n",
      "Epoch 83/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.6830 - accuracy: 0.7753\n",
      "Epoch 84/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6831 - accuracy: 0.7763\n",
      "Epoch 85/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.6794 - accuracy: 0.7754\n",
      "Epoch 86/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6798 - accuracy: 0.7759\n",
      "Epoch 87/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6752 - accuracy: 0.7765\n",
      "Epoch 88/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6740 - accuracy: 0.7785\n",
      "Epoch 89/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6718 - accuracy: 0.7784\n",
      "Epoch 90/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6701 - accuracy: 0.7782\n",
      "Epoch 91/100\n",
      "98286/98286 [==============================] - 10s 102us/sample - loss: 0.6684 - accuracy: 0.7798\n",
      "Epoch 92/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6673 - accuracy: 0.7801\n",
      "Epoch 93/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6636 - accuracy: 0.7794\n",
      "Epoch 94/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6651 - accuracy: 0.7798\n",
      "Epoch 95/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6597 - accuracy: 0.7823\n",
      "Epoch 96/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6622 - accuracy: 0.7819\n",
      "Epoch 97/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6597 - accuracy: 0.7815\n",
      "Epoch 98/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6568 - accuracy: 0.7820\n",
      "Epoch 99/100\n",
      "98286/98286 [==============================] - 10s 100us/sample - loss: 0.6518 - accuracy: 0.7845\n",
      "Epoch 100/100\n",
      "98286/98286 [==============================] - 10s 101us/sample - loss: 0.6542 - accuracy: 0.7831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b663ecf50>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neste mann på lista.seredent, unntatt kai, han var på landet... de meg eil sin rene på den står.ta dei varmter seg i piggt når de hadde sex, unntatt kai, han var på land\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 10, 'neste mann på lista', 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "stein_sentences = [line for line in kaizerbarna if \"på landet\" in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alle barna var i byen, unntatt anne, hun var på landet.',\n",
       " 'alle barna var i byen unntatt johanne, hun var på landet.',\n",
       " 'alle barna var på landet, unntatt kjell, han var på et fjell.']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stein_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
