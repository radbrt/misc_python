{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('/home/jovyan/Data/fashionmnist/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/jovyan/Data/fashionmnist/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:,1:].to_numpy()\n",
    "y = train.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.reshape((60000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd5e6ba5f90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X2[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhot = pd.get_dummies(train.iloc[:,0].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = X2[:,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape = (28, 28, 1) ))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dense(32, activation='relu'))\n",
    "classifier.add(Dense(yhot.shape[1]))\n",
    "classifier.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = categorical_crossentropy, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 283,434\n",
      "Trainable params: 283,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhot_test = pd.get_dummies(test.iloc[:,0].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhot_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,1:].to_numpy().reshape((10000, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:,:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 38s 638us/sample - loss: 0.5185 - accuracy: 0.8445 - val_loss: 0.3245 - val_accuracy: 0.8852\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 39s 646us/sample - loss: 0.2900 - accuracy: 0.8956 - val_loss: 0.2784 - val_accuracy: 0.9013\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 40s 673us/sample - loss: 0.2493 - accuracy: 0.9096 - val_loss: 0.2707 - val_accuracy: 0.8999\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 40s 669us/sample - loss: 0.2219 - accuracy: 0.9182 - val_loss: 0.2530 - val_accuracy: 0.9093\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 41s 686us/sample - loss: 0.1958 - accuracy: 0.9278 - val_loss: 0.2700 - val_accuracy: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5e6a2b4d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit( X3, yhot,\n",
    "                        epochs=5,\n",
    "                         validation_data=(X_test, yhot_test)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En kjapp forklaring av tapsfunksjonen vår, categorical_crossentropy:\n",
    "\n",
    "Output av funksjonen er en vektor med sannsynligheter for hver klasse, altså tall mellom 0 og 1. Y er en vektor med de sanne klassene, altså en vektor med 0 i alle elementer unntatt den sanne klassen, hvor vektoren er 1.\n",
    "\n",
    "Enhver funksjon som blir lavere desto mindre foskjellen mellom disse to vektorene er, vil kunne fungere som tapsfunksjon. categorical_crossentropy (her illustrert med spesialtilfellet binary_crossentropy) er som følger:\n",
    "\n",
    "\n",
    "$$-\\frac{1}{N}\\sum{y_{i}*log(p_{i}) + (1-y_{i})*log(1-p_{i})}$$\n",
    "\n",
    "For å få en litt bedre forståelse er kanskje denne kalkulatoren grei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01005033585350145"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "# i eksempelet er y=1, så tapet blir lavere jo nærmere p er 1\n",
    "p=0.99\n",
    "\n",
    "-(1*math.log(p) + 0*(1-math.log(1-p)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
